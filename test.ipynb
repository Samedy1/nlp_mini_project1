{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_probability(lamda: float, unigram_word: int, total_word: int, k: float, v: int,):\n",
    "    return (lamda * (unigram_word + k)) / (total_word + (k * v))\n",
    "\n",
    "def ngram_probability(lamda: float, ngram_count: int, prev_ngram_count: int, k: float, v: int,):\n",
    "    return (lamda * (ngram_count + k)) / (prev_ngram_count + (k * v))\n",
    "\n",
    "def addk_probability_interpolation(\n",
    "    word: str,\n",
    "    previous_words: tuple[str, str, str],\n",
    "    unigram_counts: dict[str, int],\n",
    "    bigram_counts: dict[str, int],\n",
    "    trigram_counts: dict[str, int],\n",
    "    fourgram_counts: dict[str, int],\n",
    "    k=0.1,  # Smoothing parameter\n",
    "    lambda1=0.1,\n",
    "    lambda2=0.2,\n",
    "    lambda3=0.3,\n",
    "    lambda4=0.4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Estimate the probability of a word being the next word after given previous words using linear interpolation with add-k smoothing.\n",
    "\n",
    "    Args:\n",
    "        word: The word for which to calculate the next word probability.\n",
    "        previous_words: A tuple containing the two previous words.\n",
    "        unigram_counts: A dictionary with counts of unigrams.\n",
    "        bigram_counts: A dictionary with counts of bigrams.\n",
    "        trigram_counts: A dictionary with counts of trigrams.\n",
    "        fourgram_counts: A dictionary with counts of fourgrams.\n",
    "        k: Smoothing parameter (default is 1).\n",
    "        lambda1: Weight for unigram model.\n",
    "        lambda2: Weight for bigram model.\n",
    "        lambda3: Weight for trigram model.\n",
    "        lambda4: Weight for fourgram model.\n",
    "\n",
    "    Returns:\n",
    "        The estimated probability of 'word' being the next word after 'previous_words' using linear interpolation with add-k smoothing.\n",
    "    \"\"\"\n",
    "    # Create the unigram, bigram, trigram, and fourgram tuples\n",
    "    unigram = (word,)\n",
    "    bigram = (previous_words[2], word)\n",
    "    trigram = (previous_words[1], previous_words[2], word)\n",
    "    fourgram = (previous_words[0], previous_words[1], previous_words[2], word)\n",
    "\n",
    "    # Get counts from respective count dictionaries\n",
    "    unigram_count = unigram_counts.get(unigram, 0)\n",
    "    bigram_count = bigram_counts.get(bigram, 0)\n",
    "    trigram_count = trigram_counts.get(trigram, 0)\n",
    "    fourgram_count = fourgram_counts.get(fourgram, 0)\n",
    "\n",
    "    # Total counts for normalization\n",
    "    total_word = len(tokenized_words['sentences']) \n",
    "\n",
    "    # Total unique word\n",
    "    unique_word = len(set(tokenized_words['sentences']))\n",
    "\n",
    "    unigram_prob = uni_probability(\n",
    "        lambda1, unigram_count, total_word, k, unique_word\n",
    "    )\n",
    "    bigram_prob = ngram_probability(\n",
    "        lambda2, bigram_count, unigram_count, k, unique_word\n",
    "    )\n",
    "    trigram_prob = ngram_probability(\n",
    "        lambda3, trigram_count, bigram_count, k, unique_word\n",
    "    )\n",
    "    fourgram_prob = ngram_probability(\n",
    "        lambda4, fourgram_count, trigram_count, k, unique_word\n",
    "    )\n",
    "\n",
    "    probability = unigram_prob + bigram_prob + trigram_prob + fourgram_prob\n",
    "\n",
    "    return probability;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.596638655462185\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test = addk_probability_interpolation(\n",
    "    \"test\", \n",
    "    (\"this\", \"is\", \"a\"),\n",
    "    Counter(freq_uni),\n",
    "    Counter(freq_bi),\n",
    "    Counter(freq_tri),\n",
    "    Counter(freq_four),\n",
    ")\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stackk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
