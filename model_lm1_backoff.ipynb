{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the preprocessed data from the preprocess file\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourGramWithBackOff:        \n",
    "    def __init__(self):\n",
    "\n",
    "        # preprocess\n",
    "        text_preprocessor = TextPreprocessor()\n",
    "        \n",
    "        # initialize necessary fields\n",
    "        self.unigram_freq = text_preprocessor.freq_uni\n",
    "        self.bigram_freq = text_preprocessor.freq_bi\n",
    "        self.trigram_freq = text_preprocessor.freq_tri\n",
    "        self.fourgram_freq = text_preprocessor.freq_four\n",
    "\n",
    "    def probability_uni(self, word):\n",
    "        uni_tuple = (word,)\n",
    "        total_unigrams = sum(self.unigram_freq.values())\n",
    "\n",
    "        return self.unigram_freq.get(uni_tuple, 0) / total_unigrams if total_unigrams != 0 else 0\n",
    "\n",
    "    def probability_bi(self, word1, word2):\n",
    "        bi_tuple = (word1, word2)\n",
    "        word = (word1,)\n",
    "\n",
    "        unigram_count = self.unigram_freq.get(word, 0)\n",
    "        return self.bigram_freq.get(bi_tuple, 0) / unigram_count if unigram_count != 0 else 0\n",
    "\n",
    "    def probability_tri(self, word1, word2, word3):\n",
    "        tri_tuple = (word1, word2, word3)\n",
    "        bi_tuple = (word1, word2)\n",
    "\n",
    "        bigram_count = self.bigram_freq.get(bi_tuple, 0)\n",
    "        return self.trigram_freq.get(tri_tuple, 0) / bigram_count if bigram_count != 0 else 0\n",
    "\n",
    "    def probability_four(self, word1, word2, word3, word4):\n",
    "        four_tuple = (word1, word2, word3, word4)\n",
    "        tri_tuple = (word1, word2, word3)\n",
    "\n",
    "        trigram_count = self.trigram_freq.get(tri_tuple, 0)\n",
    "        return self.fourgram_freq.get(four_tuple, 0) / trigram_count if trigram_count != 0 else 0\n",
    "\n",
    "    def probability_backoff(self, word1, word2, word3, word4):\n",
    "        fourgram_prob = self.probability_four(word1, word2, word3, word4)\n",
    "        \n",
    "        if fourgram_prob != 0 and fourgram_prob != float('inf'):\n",
    "            return fourgram_prob\n",
    "        else:\n",
    "            trigram_prob = self.probability_tri(word2, word3, word4)\n",
    "            \n",
    "            if trigram_prob != 0 and trigram_prob != float('inf'):\n",
    "                return trigram_prob\n",
    "            else:\n",
    "                bigram_prob = self.probability_bi(word3, word4)\n",
    "                \n",
    "                if bigram_prob != 0 and bigram_prob != float('inf'):\n",
    "                    return bigram_prob\n",
    "                else:\n",
    "                    unigram_prob = self.probability_uni(word4)\n",
    "                    return unigram_prob\n",
    "                \n",
    "    def predict_next_word(self, word1, word2, word3):\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(1, 5):\n",
    "            # Perform backoff starting from fourgram down to unigram\n",
    "            if(i == 1):\n",
    "                for word in self.unigram_freq.keys():\n",
    "                    probability = self.probability_four(word1, word2, word3, word[0])\n",
    "                    predictions.append((word, probability))\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                if predictions[0][1] == 0.0:\n",
    "                    predictions = []\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            elif(i == 2):\n",
    "                for word in self.unigram_freq.keys():\n",
    "                    probability = self.probability_tri(word2, word3, word[0])\n",
    "                    predictions.append((word, probability))\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                if predictions[0][1] == 0.0:\n",
    "                    predictions = []\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            elif(i == 3):\n",
    "                for word in self.unigram_freq.keys():\n",
    "                    probability = self.probability_bi(word3, word[0])\n",
    "                    predictions.append((word, probability))\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                if predictions[0][1] == 0.0:\n",
    "                    predictions = []\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                for word in self.unigram_freq.keys():\n",
    "                    probability = self.probability_uni(word[0])\n",
    "                    predictions.append((word, probability))\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                if predictions[0][1] == 0.0:\n",
    "                    predictions = []\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        # Return the word with the highest probability\n",
    "        return predictions[0][0][0]\n",
    "        \n",
    "    def generate_text(self, initial_words, num_words=10):\n",
    "        generated_text = list(initial_words)\n",
    "\n",
    "        for _ in range(num_words):\n",
    "            if len(generated_text) >= 3:\n",
    "                word1, word2, word3 = generated_text[-3:]\n",
    "            elif len(generated_text) == 2:\n",
    "                word1, word2, word3 = generated_text[0], generated_text[0], generated_text[1]\n",
    "            elif len(generated_text) == 1:\n",
    "                word1, word2, word3 = generated_text[0], generated_text[0], generated_text[0]\n",
    "            else:\n",
    "                # Handle the case where there are fewer than 3 initial words\n",
    "                raise ValueError(\"Insufficient initial words for text generation.\")\n",
    "\n",
    "            next_word = self.predict_next_word(word1, word2, word3)\n",
    "            generated_text.append(next_word)\n",
    "\n",
    "        return generated_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FourGramWithBackOff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backoff_prop = model.probability_backoff('computer', 'science', 'is', 'abc')\n",
    "backoff_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_next_word('computer', 'science', 'is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer science is the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology\n"
     ]
    }
   ],
   "source": [
    "initial_words = ['computer', 'science', 'is']\n",
    "generated_text = model.generate_text(initial_words, num_words=50)\n",
    "print(\" \".join(generated_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_back_off():\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "da87a88fed6e90d143d9d0b1bb3133bd9148111863282b0e389216736ed83b9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
