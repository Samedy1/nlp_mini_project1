{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the preprocessed data from the preprocess file\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourGramWithBackOff:        \n",
    "    def __init__(self):\n",
    "\n",
    "        # preprocess\n",
    "        text_preprocessor = TextPreprocessor()\n",
    "        \n",
    "        # initialize necessary fields\n",
    "        self.unigram_freq = text_preprocessor.freq_uni\n",
    "        self.bigram_freq = text_preprocessor.freq_bi\n",
    "        self.trigram_freq = text_preprocessor.freq_tri\n",
    "        self.fourgram_freq = text_preprocessor.freq_four\n",
    "\n",
    "    def probability_uni(self, word):\n",
    "        uni_tuple = (word,)\n",
    "        total_unigrams = sum(self.unigram_freq.values())\n",
    "\n",
    "        return self.unigram_freq.get(uni_tuple, 0) / total_unigrams if total_unigrams != 0 else 0\n",
    "\n",
    "    def probability_bi(self, word1, word2):\n",
    "        bi_tuple = (word1, word2)\n",
    "        word = (word1,)\n",
    "\n",
    "        unigram_count = self.unigram_freq.get(word, 0)\n",
    "        return self.bigram_freq.get(bi_tuple, 0) / unigram_count if unigram_count != 0 else 0\n",
    "\n",
    "    def probability_tri(self, word1, word2, word3):\n",
    "        tri_tuple = (word1, word2, word3)\n",
    "        bi_tuple = (word1, word2)\n",
    "\n",
    "        bigram_count = self.bigram_freq.get(bi_tuple, 0)\n",
    "        return self.trigram_freq.get(tri_tuple, 0) / bigram_count if bigram_count != 0 else 0\n",
    "\n",
    "    def probability_four(self, word1, word2, word3, word4):\n",
    "        four_tuple = (word1, word2, word3, word4)\n",
    "        tri_tuple = (word1, word2, word3)\n",
    "\n",
    "        trigram_count = self.trigram_freq.get(tri_tuple, 0)\n",
    "        return self.fourgram_freq.get(four_tuple, 0) / trigram_count if trigram_count != 0 else 0\n",
    "\n",
    "    def probability_backoff(self, word1, word2, word3, word4):\n",
    "        fourgram_prob = self.probability_four(word1, word2, word3, word4)\n",
    "        \n",
    "        if fourgram_prob != 0 and fourgram_prob != float('inf'):\n",
    "            return fourgram_prob\n",
    "        else:\n",
    "            trigram_prob = self.probability_tri(word2, word3, word4)\n",
    "            \n",
    "            if trigram_prob != 0 and trigram_prob != float('inf'):\n",
    "                return trigram_prob\n",
    "            else:\n",
    "                bigram_prob = self.probability_bi(word3, word4)\n",
    "                \n",
    "                if bigram_prob != 0 and bigram_prob != float('inf'):\n",
    "                    return bigram_prob\n",
    "                else:\n",
    "                    unigram_prob = self.probability_uni(word4)\n",
    "                    return unigram_prob\n",
    "                \n",
    "    def predict_next_word(self, word1, word2, word3):\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(1, 5):\n",
    "            # Perform backoff starting from fourgram down to unigram\n",
    "            if(i == 1):\n",
    "                for word in self.unigram_freq.keys():\n",
    "                    probability = self.probability_four(word1, word2, word3, word[0])\n",
    "                    predictions.append((word, probability))\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                if predictions[0][1] == 0.0:\n",
    "                    predictions = []\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            elif(i == 2):\n",
    "                for word in self.unigram_freq.keys():\n",
    "                    probability = self.probability_tri(word2, word3, word[0])\n",
    "                    predictions.append((word, probability))\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                if predictions[0][1] == 0.0:\n",
    "                    predictions = []\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            elif(i == 3):\n",
    "                for word in self.unigram_freq.keys():\n",
    "                    probability = self.probability_bi(word3, word[0])\n",
    "                    predictions.append((word, probability))\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                if predictions[0][1] == 0.0:\n",
    "                    predictions = []\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                for word in self.unigram_freq.keys():\n",
    "                    probability = self.probability_uni(word[0])\n",
    "                    predictions.append((word, probability))\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                if predictions[0][1] == 0.0:\n",
    "                    predictions = []\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        # Return the word with the highest probability\n",
    "        return predictions[0][0][0]\n",
    "        \n",
    "    def generate_text(self, initial_words, num_words=10):\n",
    "        generated_text = list(initial_words)\n",
    "\n",
    "        for _ in range(num_words):\n",
    "            if len(generated_text) >= 3:\n",
    "                word1, word2, word3 = generated_text[-3:]\n",
    "            elif len(generated_text) == 2:\n",
    "                word1, word2, word3 = generated_text[0], generated_text[0], generated_text[1]\n",
    "            elif len(generated_text) == 1:\n",
    "                word1, word2, word3 = generated_text[0], generated_text[0], generated_text[0]\n",
    "            else:\n",
    "                # Handle the case where there are fewer than 3 initial words\n",
    "                raise ValueError(\"Insufficient initial words for text generation.\")\n",
    "\n",
    "            next_word = self.predict_next_word(word1, word2, word3)\n",
    "            generated_text.append(next_word)\n",
    "\n",
    "        return generated_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FourGramWithBackOff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backoff_prop = model.probability_backoff('computer', 'science', 'is', 'abc')\n",
    "backoff_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_next_word('computer', 'science', 'is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer science is the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology\n"
     ]
    }
   ],
   "source": [
    "initial_words = ['computer', 'science', 'is']\n",
    "generated_text = model.generate_text(initial_words, num_words=50)\n",
    "print(\" \".join(generated_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_back_off():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'InterpolationAddK' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m interpolation_model \u001b[38;5;241m=\u001b[39m \u001b[43mInterpolationAddK\u001b[49m()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperplexity_interpolation_four_val\u001b[39m():\n\u001b[1;32m      4\u001b[0m     pp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'InterpolationAddK' is not defined"
     ]
    }
   ],
   "source": [
    "interpolation_model = InterpolationAddK()\n",
    "\n",
    "def perplexity_interpolation_four_val():\n",
    "    pp = 1\n",
    "    tokenized_validation = text_preprocessor.tokenize_words(text_preprocessor.validation_data)\n",
    "    tokens = tokenized_validation['sentences']\n",
    "    for i in range(3, len(tokens)):  # Adjusted loop range for fourgram\n",
    "        current_word = tokens[i]  # Adjusted indexing for fourgram\n",
    "        previous_four_gram = (tokens[i - 3], tokens[i - 2], tokens[i - 1], tokens[i])  # Construct fourgram tuple\n",
    "\n",
    "        probability = interpolation_model.n_gram_addk_probability(\n",
    "            word=current_word,\n",
    "            given_gram=previous_four_gram[:-1],  # Pass only the first three tokens for the given n-gram\n",
    "            freq_previous=interpolation_model.freq_tri,  # Frequency dictionary for trigrams\n",
    "            freq_current=interpolation_model.freq_four,  # Frequency dictionary for fourgrams\n",
    "            k=interpolation_model.k,\n",
    "        )  # Calculate probability\n",
    "\n",
    "        pp *= (1 / probability) ** (1 / len(tokens))  # Update perplexity\n",
    "\n",
    "    perplexity = pp ** (1 / (len(tokens) - 3))  # Take the nth root of the product of inverse probabilities\n",
    "    print(perplexity)\n",
    "\n",
    "perplexity_interpolation_four_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.10.12"
=======
   "version": "3.12.0"
>>>>>>> b1b9f98e99a83535645e668b16c59c3605fe1bbe
  },
  "vscode": {
   "interpreter": {
    "hash": "da87a88fed6e90d143d9d0b1bb3133bd9148111863282b0e389216736ed83b9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
