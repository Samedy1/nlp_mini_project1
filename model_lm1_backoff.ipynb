{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the preprocessed data from the preprocess file\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourGramWithBackOff:        \n",
    "    def __init__(self):\n",
    "\n",
    "        # preprocess\n",
    "        text_preprocessor = TextPreprocessor()\n",
    "        \n",
    "        # initialize necessary fields\n",
    "        self.unigram_freq = text_preprocessor.freq_uni\n",
    "        self.bigram_freq = text_preprocessor.freq_bi\n",
    "        self.trigram_freq = text_preprocessor.freq_tri\n",
    "        self.fourgram_freq = text_preprocessor.freq_four\n",
    "\n",
    "    def probability_uni(self, word):\n",
    "        uni_tuple = (word,)\n",
    "        total_unigrams = sum(self.unigram_freq.values())\n",
    "\n",
    "        return self.unigram_freq.get(uni_tuple, 0) / total_unigrams if total_unigrams != 0 else 0\n",
    "\n",
    "    def probability_bi(self, word1, word2):\n",
    "        bi_tuple = (word1, word2)\n",
    "        word = (word1,)\n",
    "\n",
    "        unigram_count = self.unigram_freq.get(word, 0)\n",
    "        return self.bigram_freq.get(bi_tuple, 0) / unigram_count if unigram_count != 0 else 0\n",
    "\n",
    "    def probability_tri(self, word1, word2, word3):\n",
    "        tri_tuple = (word1, word2, word3)\n",
    "        bi_tuple = (word1, word2)\n",
    "\n",
    "        bigram_count = self.bigram_freq.get(bi_tuple, 0)\n",
    "        return self.trigram_freq.get(tri_tuple, 0) / bigram_count if bigram_count != 0 else 0\n",
    "\n",
    "    def probability_four(self, word1, word2, word3, word4):\n",
    "        four_tuple = (word1, word2, word3, word4)\n",
    "        tri_tuple = (word1, word2, word3)\n",
    "\n",
    "        trigram_count = self.trigram_freq.get(tri_tuple, 0)\n",
    "        return self.fourgram_freq.get(four_tuple, 0) / trigram_count if trigram_count != 0 else 0\n",
    "\n",
    "    def probability_backoff(self, word1, word2, word3, word4):\n",
    "        fourgram_prob = self.probability_four(word1, word2, word3, word4)\n",
    "        \n",
    "        if fourgram_prob != 0 and fourgram_prob != float('inf'):\n",
    "            return fourgram_prob\n",
    "        else:\n",
    "            trigram_prob = self.probability_tri(word2, word3, word4)\n",
    "            \n",
    "            if trigram_prob != 0 and trigram_prob != float('inf'):\n",
    "                return trigram_prob\n",
    "            else:\n",
    "                bigram_prob = self.probability_bi(word3, word4)\n",
    "                \n",
    "                if bigram_prob != 0 and bigram_prob != float('inf'):\n",
    "                    return bigram_prob\n",
    "                else:\n",
    "                    unigram_prob = self.probability_uni(word4)\n",
    "                    return unigram_prob\n",
    "                \n",
    "    def predict_next_word(self, word1, word2, word3):\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(1, 5):\n",
    "            # Perform backoff starting from fourgram down to unigram\n",
    "            if(i == 1):\n",
    "                for word in self.unigram_freq.keys():\n",
    "                    probability = self.probability_four(word1, word2, word3, word[0])\n",
    "                    predictions.append((word, probability))\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                if predictions[0][1] == 0.0:\n",
    "                    predictions = []\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            elif(i == 2):\n",
    "                for word in self.unigram_freq.keys():\n",
    "                    probability = self.probability_tri(word2, word3, word[0])\n",
    "                    predictions.append((word, probability))\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                if predictions[0][1] == 0.0:\n",
    "                    predictions = []\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            elif(i == 3):\n",
    "                for word in self.unigram_freq.keys():\n",
    "                    probability = self.probability_bi(word3, word[0])\n",
    "                    predictions.append((word, probability))\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                if predictions[0][1] == 0.0:\n",
    "                    predictions = []\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                for word in self.unigram_freq.keys():\n",
    "                    probability = self.probability_bi(word[0])\n",
    "                    predictions.append((word, probability))\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                if predictions[0][1] == 0.0:\n",
    "                    predictions = []\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        # Return the word with the highest probability\n",
    "        return predictions[0][0][0]\n",
    "        \n",
    "    def generate_text(self, initial_words, num_words=10):\n",
    "        generated_text = list(initial_words)\n",
    "\n",
    "        for _ in range(num_words):\n",
    "            if len(generated_text) >= 3:\n",
    "                word1, word2, word3 = generated_text[-3:]\n",
    "            elif len(generated_text) == 2:\n",
    "                word1, word2, word3 = generated_text[0], generated_text[0], generated_text[1]\n",
    "            elif len(generated_text) == 1:\n",
    "                word1, word2, word3 = generated_text[0], generated_text[0], generated_text[0]\n",
    "            else:\n",
    "                # Handle the case where there are fewer than 3 initial words\n",
    "                raise ValueError(\"Insufficient initial words for text generation.\")\n",
    "\n",
    "            next_word = self.predict_next_word(word1, word2, word3)\n",
    "            generated_text.append(next_word)\n",
    "\n",
    "        return generated_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FourGramWithBackOff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backoff_prop = model.probability_backoff('computer', 'science', 'is', 'the')\n",
    "backoff_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_next_word('computer', 'science', 'is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer science is the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology\n"
     ]
    }
   ],
   "source": [
    "initial_words = ['computer', 'science', 'is']\n",
    "generated_text = model.generate_text(initial_words, num_words=50)\n",
    "print(\" \".join(generated_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation for Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_back_off():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.002155920517299"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessor = TextPreprocessor()\n",
    "backoff_model = FourGramWithBackOff()\n",
    "\n",
    "def perplexity_backoff_four_val(backoff_model):\n",
    "    pp = 1\n",
    "    tokenized_validation = text_preprocessor.tokenize_words(text_preprocessor.validation_data)\n",
    "    tokens = tokenized_validation['sentences']\n",
    "    for i in range(3, len(tokens)):  # Adjusted loop range for fourgram\n",
    "        current_word = tokens[i]  # Adjusted indexing for fourgram\n",
    "        previous_three_gram = (tokens[i - 3], tokens[i - 2], tokens[i - 1])  # Construct threegram tuple\n",
    "\n",
    "        probability = backoff_model.probability_backoff(\n",
    "            word1=tokens[i-3],\n",
    "            word2=tokens[i-2],\n",
    "            word3=tokens[i-1],\n",
    "            word4=current_word\n",
    "            \n",
    "        )  # Calculate probability using backoff model\n",
    "\n",
    "        if probability != 0:  # Exclude zero probabilities\n",
    "            pp *= (1 / probability) ** (1 / len(tokens))  # Update perplexity\n",
    "\n",
    "    perplexity = pp ** (1 / (len(tokens) - 3))  # Take the nth root of the product of inverse probabilities\n",
    "    return perplexity\n",
    "\n",
    "perplexity_backoff_four_val(backoff_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0010125547047657"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessor = TextPreprocessor()\n",
    "backoff_model = FourGramWithBackOff()\n",
    "\n",
    "def perplexity_backoff_four_val(backoff_model):\n",
    "    pp = 1\n",
    "    tokenized_validation = text_preprocessor.tokenize_words(text_preprocessor.test_data)\n",
    "    tokens = tokenized_validation['sentences']\n",
    "    for i in range(3, len(tokens)):  # Adjusted loop range for fourgram\n",
    "        current_word = tokens[i]  # Adjusted indexing for fourgram\n",
    "        previous_three_gram = (tokens[i - 3], tokens[i - 2], tokens[i - 1])  # Construct threegram tuple\n",
    "\n",
    "        probability = backoff_model.probability_backoff(\n",
    "            word1=tokens[i-3],\n",
    "            word2=tokens[i-2],\n",
    "            word3=tokens[i-1],\n",
    "            word4=current_word\n",
    "            \n",
    "        )  # Calculate probability using backoff model\n",
    "\n",
    "        if probability != 0:  # Exclude zero probabilities\n",
    "            pp *= (1 / probability) ** (1 / len(tokens))  # Update perplexity\n",
    "\n",
    "    perplexity = pp ** (1 / (len(tokens) - 3))  # Take the nth root of the product of inverse probabilities\n",
    "    return perplexity\n",
    "\n",
    "perplexity_backoff_four_val(backoff_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <s> computer science is the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology </s> <s> computational science refers to the study of computer science and information technology </s> <s> computational science refers to the '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FourGramWithBackOff()\n",
    "\n",
    "def text_generator(tri_gram):\n",
    "\n",
    "    generated_text = ' '\n",
    "    for word in tri_gram:\n",
    "        generated_text = generated_text + word + ' '\n",
    "    for i in range(0, 100):\n",
    "        next_word = model.predict_next_word(tri_gram[0], tri_gram[1], tri_gram[2])\n",
    "        tri_gram = tri_gram[1:]\n",
    "        tri_gram = list(tri_gram)\n",
    "        tri_gram.append(next_word)\n",
    "        tri_gram = tuple(tri_gram)\n",
    "        generated_text = generated_text + next_word + ' '\n",
    "    return generated_text\n",
    "    \n",
    "generated = text_generator(('<s>', 'computer', 'science'))\n",
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "da87a88fed6e90d143d9d0b1bb3133bd9148111863282b0e389216736ed83b9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
